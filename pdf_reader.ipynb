{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import streamlit as st\n",
    "from langchain_community.output_parsers.rail_parser import GuardrailsOutputParser\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "            deployment_name = \"gpt-35-turbo-16k\",\n",
    "            azure_endpoint= st.secrets['OPENAI_API_ENDPOINT'],\n",
    "            openai_api_type=\"azure\",\n",
    "            openai_api_version = \"2023-07-01-preview\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import streamlit as st\n",
    "from langchain_community.output_parsers.rail_parser import GuardrailsOutputParser\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "            deployment_name = \"gpt-35-turbo-16k\",\n",
    "            azure_endpoint= st.secrets['OPENAI_API_ENDPOINT'],\n",
    "            openai_api_type=\"azure\",\n",
    "            openai_api_version = \"2023-07-01-preview\"\n",
    "        )\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Get your API keys from Openai, you will need to create an account.\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOURAPIKEY\"\n",
    "\n",
    "\n",
    "# read in your pdf file\n",
    "pdf_reader = PdfReader()  \n",
    "\n",
    "# read data from the file and put them into a variable called text\n",
    "text = ''\n",
    "for i, page in enumerate(pdf_reader.pages):\n",
    "text = page.extract_text()\n",
    "if text:\n",
    "text += text\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "chunk_size = 512,\n",
    "chunk_overlap  = 32,\n",
    "length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(text)\n",
    "\n",
    "# Download embeddings from OpenAI\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
    "\n",
    "query = \"who are the authors of the article?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain.llms import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# Set your OpenAI API key\n",
    "#os.environ[\"OPENAI_API_KEY\"] = st.secrets[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = AzureChatOpenAI(\n",
    "            deployment_name = \"gpt-35-turbo-16k\",\n",
    "            azure_endpoint= st.secrets['OPENAI_API_ENDPOINT'],\n",
    "            openai_api_type=\"azure\",\n",
    "            openai_api_version = \"2023-07-01-preview\"\n",
    "        )\n",
    "\n",
    "# Function to read and summarize PDF files\n",
    "def summarize_pdf(file):\n",
    "    pdf_reader = PdfReader(file)\n",
    "    text = ''\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=32, length_function=len)\n",
    "    texts = text_splitter.split_text(text)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    query = \"Summarize the content of this PDF.\"\n",
    "    docs = docsearch.similarity_search(query)\n",
    "    summary = chain.run(input_documents=docs, question=query)\n",
    "    return summary\n",
    "\n",
    "# Function to handle CSV and Excel files\n",
    "def handle_csv_excel(file, file_type):\n",
    "    if file_type == 'csv':\n",
    "        df = pd.read_csv(file)\n",
    "    elif file_type == 'excel':\n",
    "        df = pd.read_excel(file)\n",
    "    \n",
    "    st.write(df.head())\n",
    "\n",
    "    # Example operation on the dataframe\n",
    "    summary = f\"The file has {df.shape[0]} rows and {df.shape[1]} columns.\"\n",
    "    return summary\n",
    "\n",
    "# Streamlit file uploader\n",
    "st.title(\"File Summarization App\")\n",
    "uploaded_file = st.file_uploader(\"Upload a PDF, CSV, or Excel file\", type=[\"pdf\", \"csv\", \"xlsx\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    file_type = uploaded_file.type\n",
    "    if file_type == \"application/pdf\":\n",
    "        st.write(\"Summarizing PDF file...\")\n",
    "        summary = summarize_pdf(uploaded_file)\n",
    "        st.write(\"Summary:\")\n",
    "        st.write(summary)\n",
    "    elif file_type == \"text/csv\":\n",
    "        st.write(\"Handling CSV file...\")\n",
    "        summary = handle_csv_excel(uploaded_file, 'csv')\n",
    "        st.write(\"Summary:\")\n",
    "        st.write(summary)\n",
    "    elif file_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "        st.write(\"Handling Excel file...\")\n",
    "        summary = handle_csv_excel(uploaded_file, 'excel')\n",
    "        st.write(\"Summary:\")\n",
    "        st.write(summary)\n",
    "    else:\n",
    "        st.write(\"Unsupported file type.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
